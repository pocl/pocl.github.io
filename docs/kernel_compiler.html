
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Kernel compiler &#8212; Portable Computing Language (PoCL) 6.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/classic.css" />
    
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Memory management in PoCL" href="memory_management.html" />
    <link rel="prev" title="OpenCL host library" href="host_library.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="memory_management.html" title="Memory management in PoCL"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="host_library.html" title="OpenCL host library"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Portable Computing Language (PoCL) 6.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="design.html" accesskey="U">Notes on internal design</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Kernel compiler</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="kernel-compiler">
<h1>Kernel compiler<a class="headerlink" href="#kernel-compiler" title="Permalink to this headline">¶</a></h1>
<p>The compilation of kernels in pocl is performed roughly as follows.</p>
<ol class="arabic">
<li><p>Produce an LLVM bitcode of the entire program.</p>
<p>This is done using ‘preprocess’ and ‘emit-llvm’ Clang actions. This
happens at clBuildProgram() time.</p>
</li>
<li><p>Link in the built-in kernel library functions.</p>
<p>The OpenCL C builtin functions are precompiled to LLVM <em>bitcode</em> libraries
residing under <code class="docutils literal notranslate"><span class="pre">lib/kernel/$TARGET</span></code>. These are linked to the kernel using
link() from lib/llvmopencl/linker.cpp. This too happens in clBuildProgram()</p>
</li>
<li><p>Produce the work-group function.</p>
<p>The single work-item kernel function is converted to a “work-group” function that
executes the kernel for all work-items in the local space. This is done
for targets that cannot execute the single work-item descriptions directly for
multiple work-item work-groups. This includes the common CPU targets that are not
optimized to the “Single Program Multiple Data” (SPMD) workloads. In contrast,
GPU architectures (SIMT or SIMD style datapaths) often can input a single kernel
description and take care of the parallel execution of multiple kernel instances
using their scheduling hardware.</p>
<p>This part is performed by target-specific code when a kernel execution
command is scheduled. Only at this point the work-group dimensions are
known, after which it is possible to produce functions of the single
kernel functions that execute the whole work-group.</p>
</li>
<li><p>Code generation for the target.</p>
<p>The work-group function (which is still in LLVM IR) of the kernel along with the launcher
functions are finally converted to the machine code of the target device. This is done in
the device layer’s implementation of the kernel run command (same as generating wg
function). For example, see <code class="docutils literal notranslate"><span class="pre">llvm_codegen()</span></code> in <code class="docutils literal notranslate"><span class="pre">lib/CL/devices/common.c</span></code>.
This function generates a dynamically loaded object of the work-group
function for actually launching the kernel. The function is called
from the CPU device layer implementations
(<code class="docutils literal notranslate"><span class="pre">pocl_basic_run()</span></code> of <code class="docutils literal notranslate"><span class="pre">lib/CL/devices/basic/basic.c</span></code>).</p>
</li>
</ol>
<section id="multiple-logical-address-spaces">
<h2>Multiple logical address spaces<a class="headerlink" href="#multiple-logical-address-spaces" title="Permalink to this headline">¶</a></h2>
<p>By default, Clang converts the OpenCL C address space qualifiers to “language”
address space identifiers, which are later converted to target-specific address
spaces. That is, e.g., for the common CPU targets with single uniform address space,
all of the OpenCL address spaces are mapped to the address space identifier 0
(the default C address space).</p>
<p>For multiple address space LLVM backends such as AMD GPUs, there are different IDs
produced for the OpenCL C address spaces, but they differ from those of the TCE backend,
etc.</p>
<p>Thus, after the Clang processing of the kernel source, the information of the original
OpenCL C address spaces is lost or is target specific, preventing or complicating the special
treatment of the pointers pointing to (logically) different address spaces (e.g. OpenCL
disjoint address space alias analysis, see <a class="reference internal" href="#opencl-optimizations"><span class="std std-ref">Other OpenCL-specific optimizations</span></a>).</p>
</section>
<section id="work-group-function-generation">
<h2>Work group function generation<a class="headerlink" href="#work-group-function-generation" title="Permalink to this headline">¶</a></h2>
<p>The work-group function simply produces the execution of the whole local
space, i.e., it executes the kernel code for all work-items in a work-group.
Currently one work-group function is produced for each different local
sizes enqueued with <code class="docutils literal notranslate"><span class="pre">clEnqueueNDRangeKernel</span></code>.</p>
<p>Producing the work-group functions sounds trivial at first, but due to the work-group
barriers, it becomes slightly complex to perform statically (at compile time). That is,
one cannot simply create a loop around the whole kernel function, but execute
each region between the barriers for each work-item before proceedings to the
next region, etc.</p>
<p>The work-group functions are produced from a single kernel description using
a set of LLVM passes in pocl which are described in the following. Most of
the passes can be omitted for targets which input single kernel descriptions
to the instruction set. The source code for the passes is located
inside <em>lib/llvmopencl</em>.</p>
<p>The most complex part of the work-group generation is the part that analyzes
the “barrier regions” and produces static execution of multiple work-items
for them.</p>
<p>The part that analyzes the barrier regions (chains of basic block between
barriers) is done in <code class="docutils literal notranslate"><span class="pre">Kernel::getParallelRegions</span></code>. It analyzes the kernel
and returns a set of <code class="docutils literal notranslate"><span class="pre">ParallelRegion</span></code> objects (set of basic blocks constituting
a single-entry single-exit control flow graphs) inside the kernel to form
the basis for the multi-WI execution. These regions should be executed for
all work-items before proceeding to the next region. However, it is important
to note that the work-items can execute the regions in any order due to the
parallel semantics of OpenCL C.</p>
<p>After the <code class="docutils literal notranslate"><span class="pre">ParallelRegions</span></code> have been formed, the static multiple
work-item execution can be produced in multiple ways.</p>
<p>Currently, three styles of output are supported for the work-group functions:
“fully replicated” (<code class="docutils literal notranslate"><span class="pre">WorkitemReplication</span></code>), “work-item loops” (<code class="docutils literal notranslate"><span class="pre">WorkitemLoops</span></code>)
and “cbs” (continuation-based synchronization).</p>
<p>The WorkitemReplication can be interesting for smaller WG sizes and static multi-issue machines (VLIW);
it simply duplicates the code for the different work-items to produce the work-groups.</p>
<p>The WorkitemLoops produces loops around the parallel regions that loop across the
local space. The loops are annotated as parallel using the LLVM parallel loop
annotation. This helps in producing vectorized versions of the work-group
functions using the plain LLVM inner loop vectorizer.</p>
<p>The CBS method rectifies a corner case with PoCL’s WILoops workgroup generation method,
related to barriers inside loops:</p>
<p>The OpenCL 1.2 page on barrier states:
“If barrier is inside a loop, all work-items must execute the barrier for each
iteration of the loop before any are allowed to continue execution beyond the barrier”</p>
<p>Meanwhile OpenCL 3.0 states:
“If the barrier is inside a loop, then all work-items in the work-group must execute
the barrier on each iteration of the loop if any work-item executes the barrier on that iteration.”</p>
<p>OpenCL 3.0 specification is quite clear that a barrier only has an impact <em>if</em> it is reached by any work-item.
WILoops relies on the more strict interpretation of the OpenCL 1.0-2.x restriction on barriers inside loops,
which can unfortunately break some legal OpenCL 3.0 code. CBS does not suffer from this problem,
however it is also harder to achieve same level of ILP through CBS as with the more static PoCL’s default method, therefore it currently is
not the default method.</p>
<p>Because in <code class="docutils literal notranslate"><span class="pre">WorkitemLoops</span></code> there are only a subset of work-items “alive”
at the same time (the current parallel region iteration), one has to store
variables produced by the work-item in case they are used in other parallel
regions (work-item loops). These variables are stored in “context arrays” and
restore code is injected before the later uses of the variables.</p>
<p>The context data treatment is not needed for the <code class="docutils literal notranslate"><span class="pre">WorkitemReplication</span></code> method because in
that case, all the work-items are “live” at the same time, and the work-item variables
are replicated as scalars for each work-item which are visible across the whole
work-group function without needing to restore them separately.</p>
</section>
<section id="work-group-autovectorization">
<h2>Work-group autovectorization<a class="headerlink" href="#work-group-autovectorization" title="Permalink to this headline">¶</a></h2>
<p>The work-group functions can be vectorized “horizontally” (across multiple
work-items in the work-group function) by using the
<code class="docutils literal notranslate"><span class="pre">WorkitemLoops</span></code> to produce parallel loops for the parallel regions. These
loops are then attempted to vectorized using the standard LLVM’s inner-loop
vectorizer.</p>
<p>In order to improve vectorization opportunities, some of the “outer loops” (loops inside the
kernels written by the OpenCL C programmer) are converted to parallel inner loops
using a pocl pass called <code class="docutils literal notranslate"><span class="pre">ImplicitLoopBarriers</span></code>. It adds an implicit barrier to the
beginning of the loop body to force its treatment similarly to a loop with work-group
barriers (which are executed “horizontally”; each work-item executes the same iteration
of the kernel loop before proceeding to the next one). This allows parallelizing work-items
across the work-group per kernel for-loop iteration, potentially leading to easier
horizontal vectorization. The idea is similar to loop switching where the parallel work-item
loop is switched with the kernel for-loop.</p>
<p>An example should clarify this. A kernel where the work-item loop is created around
the kernel’s loop (here <em>parallel_WI_loop</em> marks the place where the work-item loop
is created).</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="n">__kernel</span>
<span class="kt">void</span><span class="w"> </span><span class="n">DCT</span><span class="p">(</span><span class="n">__global</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span>
<span class="w">         </span><span class="n">__global</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span>
<span class="w">         </span><span class="n">__global</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dct8x8</span><span class="p">,</span>
<span class="w">         </span><span class="n">__local</span><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inter</span><span class="p">,</span>
<span class="w">         </span><span class="k">const</span><span class="w">    </span><span class="n">uint</span><span class="w">    </span><span class="n">width</span><span class="p">,</span>
<span class="w">         </span><span class="k">const</span><span class="w">    </span><span class="n">uint</span><span class="w">    </span><span class="n">blockWidth</span><span class="p">,</span>
<span class="w">         </span><span class="k">const</span><span class="w">    </span><span class="n">uint</span><span class="w">    </span><span class="n">inverse</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="cm">/* ... */</span>
<span class="cm">/* parallel_WI_loop { */</span>
<span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="n">uint</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">blockWidth</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="n">uint</span><span class="w"> </span><span class="n">index1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">inverse</span><span class="p">)</span><span class="o">?</span><span class="w"> </span><span class="n">i</span><span class="o">*</span><span class="n">blockWidth</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockWidth</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">        </span><span class="n">uint</span><span class="w"> </span><span class="n">index2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">getIdx</span><span class="p">(</span><span class="n">groupIdx</span><span class="p">,</span><span class="w"> </span><span class="n">groupIdy</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">blockWidth</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="p">);</span>

<span class="w">        </span><span class="n">acc</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">dct8x8</span><span class="p">[</span><span class="n">index1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">index2</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">inter</span><span class="p">[</span><span class="n">j</span><span class="o">*</span><span class="n">blockWidth</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">acc</span><span class="p">;</span>
<span class="cm">/* } */</span>
<span class="w">    </span><span class="n">barrier</span><span class="p">(</span><span class="n">CLK_LOCAL_MEM_FENCE</span><span class="p">);</span>
<span class="w">    </span><span class="cm">/* ... */</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The kernel-loop cannot be easily vectorized as the <code class="docutils literal notranslate"><span class="pre">blockWidth</span></code> is a kernel parameter,
i.e., the vectorizer does not know how many times the loop iterates. Also, for vectorizing
intra kernel-loops the compiler has to perform the regular sequential C alias analysis to
figure out whether and how the loop iterations are dependent on each other.</p>
<p>In contrast, when we are able to place the parallel work-item loop <em>inside</em> the
kernel-loop, we create a potentially more easily vectorizable loop that executes
operations from multiple work-items in parallel:</p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cm">/* ... */</span>
<span class="k">for</span><span class="p">(</span><span class="n">uint</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">blockWidth</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="o">++</span><span class="p">)</span>
<span class="p">{</span>
<span class="cm">/* parallel_WI_loop { */</span>
<span class="w">  </span><span class="n">uint</span><span class="w"> </span><span class="n">index1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">inverse</span><span class="p">)</span><span class="o">?</span><span class="w"> </span><span class="n">i</span><span class="o">*</span><span class="n">blockWidth</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockWidth</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">  </span><span class="n">uint</span><span class="w"> </span><span class="n">index2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">getIdx</span><span class="p">(</span><span class="n">groupIdx</span><span class="p">,</span><span class="w"> </span><span class="n">groupIdy</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">blockWidth</span><span class="p">,</span><span class="w"> </span><span class="n">width</span><span class="p">);</span>

<span class="w">  </span><span class="n">acc</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">dct8x8</span><span class="p">[</span><span class="n">index1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">index2</span><span class="p">];</span>
<span class="w">  </span><span class="cm">/* } */</span>
<span class="w">  </span><span class="cm">/* implicit barrier added here */</span>
<span class="p">}</span>
<span class="n">inter</span><span class="p">[</span><span class="n">j</span><span class="o">*</span><span class="n">blockWidth</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">acc</span><span class="p">;</span>
<span class="n">barrier</span><span class="p">(</span><span class="n">CLK_LOCAL_MEM_FENCE</span><span class="p">);</span>

<span class="cm">/* ... */</span>
</pre></div>
</div>
<p>The difficulty with this pass is that, of course, we need to make sure it is legal to
add the barrier. The OpenCL barrier semantics require either all or none of the WIs to
reach the barrier at each iteration. This is satisfied at least when</p>
<ul class="simple">
<li><p>The loop exit condition does not depend on the WI, and</p></li>
<li><p>all or none of the WIs always enter the loop.</p></li>
</ul>
<p>In order to prove these cases, a pass called <code class="docutils literal notranslate"><span class="pre">VariableUniformityAnalysis</span></code> is used to
separate variables that are <em>uniform</em> (same for all work-items) and <em>variable</em> (vary
between work-items). It falls back to <em>variable</em> in case it cannot prove the
uniformity.</p>
</section>
<section id="creating-the-work-group-function-launchers">
<span id="wg-functions"></span><h2>Creating the work-group function launchers<a class="headerlink" href="#creating-the-work-group-function-launchers" title="Permalink to this headline">¶</a></h2>
<p>The kernel compiler creates functions for launching the work-group functions that
are built into the same module as the kernel. These functions can be used as
access points from the host code or from separate control/scheduler code at the device
side.</p>
<p><code class="docutils literal notranslate"><span class="pre">Workgroup</span></code> pass creates a launcher which calls the work-group function using the arguments
passed from the host side. It also setups a “context struct” which contains the data needed
by functions that query the work-group ids etc. This context struct is added as a new argument
to the original kernel argument list.</p>
<p><code class="docutils literal notranslate"><span class="pre">Workgroup</span></code> generates two versions for launching the kernel which are used to
depending which style of parameter passing is desired:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">KERNELNAME_workgroup()</span></code></p></li>
</ul>
<blockquote>
<div><p>for the case where the host and device shares
a single memory (the basic CPU host+device setup). Scalars are passes directly in the
argument array and everything resides in the default address space 0.</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">KERNELNAME_workgroup_fast()</span></code></p></li>
</ul>
<blockquote>
<div><p>can be used when there is a separate argument space located in a separate global
address space (from the device point of view). This assumes that buffer arguments (pointers) are
passed directly as pointer values and scalar values are also passed
as pointers to objects in an “argument space” in the global memory (that is
accessible from the host). Explicit global address space identifier is used to access
the argument data.</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">KERNELNAME_workgroup_argbuffer()</span></code></p></li>
</ul>
<blockquote>
<div><p>creates a work group launcher with all the argument data passed
in a single argument buffer. All argument values, including pointers
are stored directly in the argument buffer with natural alignment.
The rules for populating the buffer are those of the HSA kernel calling convention.</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">phsa_kernel.KERNELNAME_grid_launcher()</span></code></p></li>
</ul>
<blockquote>
<div><p>Creates a launcher function that executes all work-items in the grid by
launching a given work-group function for all work-group ids.</p>
<p>The function adheres to the PHSA calling convention where the first two
arguments are for PHSA’s context data, and the third one is the argument
buffer.</p>
</div></blockquote>
<p>NOTE: There’s a plan to remove the “fast” workgroup function and unify the way the
workgroups are called from the host code.</p>
</section>
<section id="assisting-transformations">
<h2>Assisting transformations<a class="headerlink" href="#assisting-transformations" title="Permalink to this headline">¶</a></h2>
<p>Several transformations are done to the LLVM bytecode to assist in the work-group
generation effort. Most of them are required by the actual parallel region formation.
Some of them are listed in the following:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Flatten</span></code></p></li>
</ul>
<blockquote>
<div><p>Fully inlines everything inside the kernel so there are no function
calls in the resulting kernel function. It does it by adding the LLVM attribute <code class="docutils literal notranslate"><span class="pre">AlwaysInLine</span></code>
to all child functions of the kernel after which the LLVM pass <code class="docutils literal notranslate"><span class="pre">-always-inline</span></code>
is used to actually perform the inlining. This pass is not strictly required unless
the child functions of the kernel contain barrier calls.</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">WorkitemHandlerChooser</span></code></p></li>
</ul>
<blockquote>
<div><p>Does the choice of how to produce the work-group
functions for the kernel at hand (the loops or the full replication).</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">PHIsToAllocas</span></code></p></li>
</ul>
<blockquote>
<div><p>Required by the <code class="docutils literal notranslate"><span class="pre">WorkitemLoops</span></code> but not by the <code class="docutils literal notranslate"><span class="pre">WorkitemReplication</span></code> work-group
function generation method.
It converts all PHIs to allocas in order to make it possible to inject context restore code
in the beginning of join points. This is due to the limitation that PHI nodes must
be at the beginning of the basic blocks and in some cases we need to restore
variables (load from a context array in memory) used by the PHI nodes because
they originate from a different parallel region. It is similar to <code class="docutils literal notranslate"><span class="pre">-reg2mem</span></code>
of LLVM except that it touches only PHI nodes.</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">AllocasToEntry</span></code></p></li>
</ul>
<blockquote>
<div><p>Can be used by targets that do not support dynamic stack objects to
move all stack allocations to the function entry block.</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">GenerateHeader</span></code></p></li>
</ul>
<blockquote>
<div><p>This pass is used to produce a metadata file of the kernel. The file contains
information of the argument types that are used by the host side. The data is
passed to the host side via a plugin module that contains a struct with the info.
The name, GenerateHeader, comes from this. It generates a C header file with the
info which is compiled to the plugin module. It is clear that this way of
retrieving the metadata is very cumbersome and slow, and the functionality is
being refactored to use <code class="docutils literal notranslate"><span class="pre">libClang</span></code> directly from the host code to retrieve
the information.</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">AutomaticLocals</span></code></p></li>
</ul>
<blockquote>
<div><p>This pass is converts the automatic local buffers
to kernel arguments. This is to enforce the similar treatment of the both
types of local buffers, the ones passed as arguments and the ones instantiated
in the kernel.</p>
</div></blockquote>
</section>
<section id="other-opencl-specific-optimizations">
<span id="opencl-optimizations"></span><h2>Other OpenCL-specific optimizations<a class="headerlink" href="#other-opencl-specific-optimizations" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">WorkitemAliasAnalyzer</span></code></p></li>
</ul>
<blockquote>
<div><p>Adds OpenCL-specific information to the alias analyzer. Currently exploits the
fact that accesses from two work-items cannot alias within the same “parallel
region” and that the OpenCL C address spaces are disjoint (accesses to different
address spaces do not alias).</p>
</div></blockquote>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Kernel compiler</a><ul>
<li><a class="reference internal" href="#multiple-logical-address-spaces">Multiple logical address spaces</a></li>
<li><a class="reference internal" href="#work-group-function-generation">Work group function generation</a></li>
<li><a class="reference internal" href="#work-group-autovectorization">Work-group autovectorization</a></li>
<li><a class="reference internal" href="#creating-the-work-group-function-launchers">Creating the work-group function launchers</a></li>
<li><a class="reference internal" href="#assisting-transformations">Assisting transformations</a></li>
<li><a class="reference internal" href="#other-opencl-specific-optimizations">Other OpenCL-specific optimizations</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="host_library.html"
                        title="previous chapter">OpenCL host library</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="memory_management.html"
                        title="next chapter">Memory management in PoCL</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/kernel_compiler.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="memory_management.html" title="Memory management in PoCL"
             >next</a> |</li>
        <li class="right" >
          <a href="host_library.html" title="OpenCL host library"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Portable Computing Language (PoCL) 6.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="design.html" >Notes on internal design</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Kernel compiler</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2010-2023 PoCL developers.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.3.2.
    </div>
  </body>
</html>